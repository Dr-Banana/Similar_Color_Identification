import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from scipy.signal import find_peaks


class ClusterMethod:
    def __init__(self, path):
        self.img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)
        self.img_vector = self.img.reshape(-1, 3)
        self.n_refs = 10
        self.max_cluster = 10
        self.ssd = []

    def rgb_to_lab(self):
        """
        Converts a list of RGB colors to the LAB color space using OpenCV.

        Parameters:
            rgb_colors (list of tuples): The list of RGB colors to convert.

        Returns:
            list of tuples: The corresponding list of LAB colors.
        """
        # Convert the colors to the LAB color space
        rgb_colors = self.img
        lab_colors = []
        for row in rgb_colors:
            lab_row = []
            for color in row:
                # Convert the color to a 1x1 pixel image in the RGB color space
                img = np.array([[color]])
                # Convert the pixel to the LAB color space
                lab_color = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[0][0]
                # Append the LAB color to the row
                lab_row.append(lab_color)
            # Append the row to the list
            lab_colors.append(lab_row)
        lab_colors = np.array(lab_colors[0])
        return lab_colors

    def ElbowMethod(self):
        # Convert image to 1D array
        max_k = self.max_cluster
        img_array = np.float32(self.img.reshape((-1, 3)))

        # Initialize variables
        dists = []
        k_vals = range(1, max_k + 1)

        # Calculate distortion for each value of k
        for k in k_vals:
            kmeans = KMeans(n_clusters=k, n_init="auto")
            kmeans.fit(img_array)
            dists.append(kmeans.inertia_)

        # Calculate elbow point
        diffs = np.diff(dists)
        elbow_point = diffs.argmax() + 1

        # Return best k value
        return elbow_point

    def NoC(self):
        lab_roi = cv2.cvtColor(self.img, cv2.COLOR_RGB2LAB)
        # Calculate the histogram of each channel
        hist_l, _ = np.histogram(lab_roi[:, 0], bins=256, range=(0, 256))
        hist_a, _ = np.histogram(lab_roi[:, 1], bins=256, range=(0, 256))
        hist_b, _ = np.histogram(lab_roi[:, 2], bins=256, range=(0, 256))
        # Find the peaks in each histogram
        peaks_l, _ = find_peaks(hist_l, distance=10)
        peaks_a, _ = find_peaks(hist_a, distance=10)
        peaks_b, _ = find_peaks(hist_b, distance=10)
        if np.std(hist_l) > len(peaks_l):
            num_clusters = int(np.floor((np.log(np.std(hist_l) / len(peaks_l))))) * (
                max(len(peaks_a), len(peaks_b)))+min(len(peaks_a), len(peaks_b))+1
        else:
            num_clusters = 2
        return num_clusters

    def GapStatistic(self):
        X = self.img_vector
        # Compute the reference distribution of within-cluster sum of squares (wcss)
        # using a set of reference datasets generated by bootstrapping the data
        nrefs = 5
        max_clusters = self.max_cluster
        refs = np.zeros((X.shape[1], max_clusters - 1, nrefs))
        for k in range(1, max_clusters):
            for i in range(nrefs):
                Xb = np.random.random_sample(size=X.shape)
                km = KMeans(k, n_init="auto")
                km.fit(Xb)
                refs[:, k - 1, i] = km.inertia_

        # Compute the wcss of the input data for different numbers of clusters
        ks = range(1, max_clusters)
        wcss = np.zeros(len(ks))
        for i, k in enumerate(ks):
            km = KMeans(k, n_init="auto")
            km.fit(X)
            wcss[i] = km.inertia_

        # Compute the gap statistic and the standard deviation of the reference distribution
        gaps = np.log(refs.mean(axis=2)) - np.log(wcss)
        stds = np.sqrt(1 + 1 / nrefs) * refs.std(axis=2)

        # Find the first k such that gap(k) - gap(k+1) + std(k+1) <= 0
        for i, (gap, std) in enumerate(zip(gaps, stds)):
            if i == len(gaps) - 1:
                break
            if gap[i] - gap[i + 1] + std[i + 1] <= 0:
                return i + 1

        # If no k satisfies the criterion, return the maximum k
        return max_clusters

    def cluster_image(self, k, title):
        # Reshape the image into a 2D array of pixels
        pixels = self.img.reshape(-1, 3)

        # Perform k-means clustering on the pixels
        kmeans = KMeans(n_clusters=k, random_state=0, n_init="auto").fit(pixels)
        labels = kmeans.labels_
        k = max(labels)+1
        # Assign each pixel to its nearest centroid
        labels = kmeans.predict(pixels)

        # Reshape the labels back into the original image shape
        clustered = labels.reshape(self.img.shape[:2])

        # Plot the clustered image
        plt.imshow(clustered)
        plt.axis('off')
        plt.title('k = ' + str(k)+" calculated by "+title)
        plt.show()

class GapStatistic:
    def __init__(self, path, n_refs=10, random_state=0):
        self.n_refs = n_refs
        self.random_state = random_state

    def fit(self, X, ks=range(1, 10)):
        # Calculate the within-cluster dispersion for each K
        wcss = []
        for k in ks:
            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init="auto")
            kmeans.fit(X)
            wcss.append(kmeans.inertia_)

        # Generate reference datasets and calculate their dispersion
        disp_refs = np.zeros(self.n_refs)
        for i in range(self.n_refs):
            random_data = np.random.rand(*X.shape)
            random_data = random_data * (X.max() - X.min()) + X.min()
            kmeans = KMeans(n_clusters=len(ks), random_state=self.random_state, n_init="auto")
            kmeans.fit(random_data)
            disp_refs[i] = kmeans.inertia_

        # Calculate the gap statistic for each K
        gap = np.log(disp_refs.mean()) - np.log(wcss)

        # Find the optimal number of clusters
        self.best_k = np.argmax(gap) + 1

        return self.best_k